<!DOCTYPE html>
<!--[if IE]><![endif]-->
<html>

  <head>
    <meta charset="utf-8">
      <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1">
      <title>Class LocalLLMClient </title>
      <meta name="viewport" content="width=device-width">
      <meta name="title" content="Class LocalLLMClient ">
    
    <meta name="description" content="Implements the  interface for local language model services, supporting both OpenAI-compatible and LM Studio formats. The client handles prompt validation, token limits, and response deserialization.">
      <link rel="shortcut icon" href="../favicon.ico">
      <link rel="stylesheet" href="../styles/docfx.vendor.min.css">
      <link rel="stylesheet" href="../styles/docfx.css">
      <link rel="stylesheet" href="../styles/main.css">
      <meta property="docfx:navrel" content="../toc.html">
      <meta property="docfx:tocrel" content="toc.html">
    
    
    
  </head>
  <body data-spy="scroll" data-target="#affix" data-offset="120">
    <div id="wrapper">
      <header>

        <nav id="autocollapse" class="navbar navbar-inverse ng-scope" role="navigation">
          <div class="container">
            <div class="navbar-header">
              <button type="button" class="navbar-toggle" data-toggle="collapse" data-target="#navbar">
                <span class="sr-only">Toggle navigation</span>
                <span class="icon-bar"></span>
                <span class="icon-bar"></span>
                <span class="icon-bar"></span>
              </button>

              <a class="navbar-brand" href="../index.html">
                <img id="logo" class="svg" src="../logo.svg" alt="">
              </a>
            </div>
            <div class="collapse navbar-collapse" id="navbar">
              <form class="navbar-form navbar-right" role="search" id="search">
                <div class="form-group">
                  <input type="text" class="form-control" id="search-query" placeholder="Search" autocomplete="off">
                </div>
              </form>
            </div>
          </div>
        </nav>

        <div class="subnav navbar navbar-default">
          <div class="container hide-when-search" id="breadcrumb">
            <ul class="breadcrumb">
              <li></li>
            </ul>
          </div>
        </div>
      </header>
      <div role="main" class="container body-content hide-when-search">

        <div class="sidenav hide-when-search">
          <a class="btn toc-toggle collapse" data-toggle="collapse" href="#sidetoggle" aria-expanded="false" aria-controls="sidetoggle">Show / Hide Table of Contents</a>
          <div class="sidetoggle collapse" id="sidetoggle">
            <div id="sidetoc"></div>
          </div>
        </div>
        <div class="article row grid-right">
          <div class="col-md-10">
            <article class="content wrap" id="_content" data-uid="VulcanAI.Core.LLM.LocalLLMClient">



  <h1 id="VulcanAI_Core_LLM_LocalLLMClient" data-uid="VulcanAI.Core.LLM.LocalLLMClient" class="text-break">Class LocalLLMClient</h1>
  <div class="markdown level0 summary"><p>Implements the <a class="xref" href="VulcanAI.Core.LLM.ILLMClient.html">ILLMClient</a> interface for local language model services,
supporting both OpenAI-compatible and LM Studio formats. The client handles prompt
validation, token limits, and response deserialization.</p>
</div>
  <div class="markdown level0 conceptual"></div>
  <div class="inheritance">
    <h5>Inheritance</h5>
    <div class="level0"><a class="xref" href="https://learn.microsoft.com/dotnet/api/system.object">object</a></div>
    <div class="level1"><span class="xref">LocalLLMClient</span></div>
  </div>
  <div class="implements">
    <h5>Implements</h5>
    <div><a class="xref" href="VulcanAI.Core.LLM.ILLMClient.html">ILLMClient</a></div>
  </div>
  <div class="inheritedMembers">
    <h5>Inherited Members</h5>
    <div>
      <a class="xref" href="https://learn.microsoft.com/dotnet/api/system.object.equals#system-object-equals(system-object)">object.Equals(object)</a>
    </div>
    <div>
      <a class="xref" href="https://learn.microsoft.com/dotnet/api/system.object.equals#system-object-equals(system-object-system-object)">object.Equals(object, object)</a>
    </div>
    <div>
      <a class="xref" href="https://learn.microsoft.com/dotnet/api/system.object.gethashcode">object.GetHashCode()</a>
    </div>
    <div>
      <a class="xref" href="https://learn.microsoft.com/dotnet/api/system.object.gettype">object.GetType()</a>
    </div>
    <div>
      <a class="xref" href="https://learn.microsoft.com/dotnet/api/system.object.memberwiseclone">object.MemberwiseClone()</a>
    </div>
    <div>
      <a class="xref" href="https://learn.microsoft.com/dotnet/api/system.object.referenceequals">object.ReferenceEquals(object, object)</a>
    </div>
    <div>
      <a class="xref" href="https://learn.microsoft.com/dotnet/api/system.object.tostring">object.ToString()</a>
    </div>
  </div>
  <h6><strong>Namespace</strong>: <a class="xref" href="VulcanAI.html">VulcanAI</a>.<a class="xref" href="VulcanAI.Core.html">Core</a>.<a class="xref" href="VulcanAI.Core.LLM.html">LLM</a></h6>
  <h6><strong>Assembly</strong>: VulcanAI.dll</h6>
  <h5 id="VulcanAI_Core_LLM_LocalLLMClient_syntax">Syntax</h5>
  <div class="codewrapper">
    <pre><code class="lang-csharp hljs">public class LocalLLMClient : ILLMClient</code></pre>
  </div>
  <h3 id="constructors">Constructors
</h3>
  <span class="small pull-right mobile-hide">
    <span class="divider">|</span>
    <a href="https://github.com/StevenGann/VulcanAI/new/main/apiSpec/new?filename=VulcanAI_Core_LLM_LocalLLMClient__ctor_VulcanAI_Core_Interfaces_IHttpClient_System_String_System_String_Microsoft_Extensions_Logging_ILogger_VulcanAI_Core_LLM_LocalLLMClient__System_Boolean_.md&amp;value=---%0Auid%3A%20VulcanAI.Core.LLM.LocalLLMClient.%23ctor(VulcanAI.Core.Interfaces.IHttpClient%2CSystem.String%2CSystem.String%2CMicrosoft.Extensions.Logging.ILogger%7BVulcanAI.Core.LLM.LocalLLMClient%7D%2CSystem.Boolean)%0Asummary%3A%20&#39;*You%20can%20override%20summary%20for%20the%20API%20here%20using%20*MARKDOWN*%20syntax&#39;%0A---%0A%0A*Please%20type%20below%20more%20information%20about%20this%20API%3A*%0A%0A">Edit this page</a>
  </span>
  <span class="small pull-right mobile-hide">
    <a href="https://github.com/StevenGann/VulcanAI/blob/main/VulcanAI/Core/LLM/LocalLLMClient.cs/#L127">View Source</a>
  </span>
  <a id="VulcanAI_Core_LLM_LocalLLMClient__ctor_" data-uid="VulcanAI.Core.LLM.LocalLLMClient.#ctor*"></a>
  <h4 id="VulcanAI_Core_LLM_LocalLLMClient__ctor_VulcanAI_Core_Interfaces_IHttpClient_System_String_System_String_Microsoft_Extensions_Logging_ILogger_VulcanAI_Core_LLM_LocalLLMClient__System_Boolean_" data-uid="VulcanAI.Core.LLM.LocalLLMClient.#ctor(VulcanAI.Core.Interfaces.IHttpClient,System.String,System.String,Microsoft.Extensions.Logging.ILogger{VulcanAI.Core.LLM.LocalLLMClient},System.Boolean)">LocalLLMClient(IHttpClient, string, string, ILogger&lt;LocalLLMClient&gt;, bool)</h4>
  <div class="markdown level1 summary"><p>Initializes a new instance of the <a class="xref" href="VulcanAI.Core.LLM.LocalLLMClient.html">LocalLLMClient</a> class.</p>
</div>
  <div class="markdown level1 conceptual"></div>
  <h5 class="declaration">Declaration</h5>
  <div class="codewrapper">
    <pre><code class="lang-csharp hljs">public LocalLLMClient(IHttpClient httpClient, string model, string baseUrl, ILogger&lt;LocalLLMClient&gt; logger, bool useOpenAIFormat = true)</code></pre>
  </div>
  <h5 class="parameters">Parameters</h5>
  <table class="table table-bordered table-condensed">
    <thead>
      <tr>
        <th>Type</th>
        <th>Name</th>
        <th>Description</th>
      </tr>
    </thead>
    <tbody>
      <tr>
        <td><a class="xref" href="VulcanAI.Core.Interfaces.IHttpClient.html">IHttpClient</a></td>
        <td><span class="parametername">httpClient</span></td>
        <td><p>The HTTP client used to communicate with the LLM service.</p>
</td>
      </tr>
      <tr>
        <td><a class="xref" href="https://learn.microsoft.com/dotnet/api/system.string">string</a></td>
        <td><span class="parametername">model</span></td>
        <td><p>The name of the language model to use.</p>
</td>
      </tr>
      <tr>
        <td><a class="xref" href="https://learn.microsoft.com/dotnet/api/system.string">string</a></td>
        <td><span class="parametername">baseUrl</span></td>
        <td><p>The base URL of the LLM service.</p>
</td>
      </tr>
      <tr>
        <td><a class="xref" href="https://learn.microsoft.com/dotnet/api/microsoft.extensions.logging.ilogger-1">ILogger</a>&lt;<a class="xref" href="VulcanAI.Core.LLM.LocalLLMClient.html">LocalLLMClient</a>&gt;</td>
        <td><span class="parametername">logger</span></td>
        <td><p>The logger instance for recording diagnostic information.</p>
</td>
      </tr>
      <tr>
        <td><a class="xref" href="https://learn.microsoft.com/dotnet/api/system.boolean">bool</a></td>
        <td><span class="parametername">useOpenAIFormat</span></td>
        <td><p>Whether to use the OpenAI API format for requests. If false, uses LM Studio format.</p>
</td>
      </tr>
    </tbody>
  </table>
  <h5 id="VulcanAI_Core_LLM_LocalLLMClient__ctor_VulcanAI_Core_Interfaces_IHttpClient_System_String_System_String_Microsoft_Extensions_Logging_ILogger_VulcanAI_Core_LLM_LocalLLMClient__System_Boolean__remarks">Remarks</h5>
  <div class="markdown level1 remarks"><p>The client supports two request formats:</p>
<ol>
<li>OpenAI format: Uses the standard OpenAI API request structure</li>
<li>LM Studio format: Uses a simplified request structure compatible with LM Studio
Both formats use the same endpoint (/v1/chat/completions) but with different request bodies.</li>
</ol>
</div>
  <h3 id="properties">Properties
</h3>
  <span class="small pull-right mobile-hide">
    <span class="divider">|</span>
    <a href="https://github.com/StevenGann/VulcanAI/new/main/apiSpec/new?filename=VulcanAI_Core_LLM_LocalLLMClient_MaxPromptLength.md&amp;value=---%0Auid%3A%20VulcanAI.Core.LLM.LocalLLMClient.MaxPromptLength%0Asummary%3A%20&#39;*You%20can%20override%20summary%20for%20the%20API%20here%20using%20*MARKDOWN*%20syntax&#39;%0A---%0A%0A*Please%20type%20below%20more%20information%20about%20this%20API%3A*%0A%0A">Edit this page</a>
  </span>
  <span class="small pull-right mobile-hide">
    <a href="https://github.com/StevenGann/VulcanAI/blob/main/VulcanAI/Core/LLM/LocalLLMClient.cs/#L35">View Source</a>
  </span>
  <a id="VulcanAI_Core_LLM_LocalLLMClient_MaxPromptLength_" data-uid="VulcanAI.Core.LLM.LocalLLMClient.MaxPromptLength*"></a>
  <h4 id="VulcanAI_Core_LLM_LocalLLMClient_MaxPromptLength" data-uid="VulcanAI.Core.LLM.LocalLLMClient.MaxPromptLength">MaxPromptLength</h4>
  <div class="markdown level1 summary"><p>Gets or sets the maximum length of prompts that can be sent to the LLM.</p>
</div>
  <div class="markdown level1 conceptual"></div>
  <h5 class="declaration">Declaration</h5>
  <div class="codewrapper">
    <pre><code class="lang-csharp hljs">public int MaxPromptLength { get; set; }</code></pre>
  </div>
  <h5 class="propertyValue">Property Value</h5>
  <table class="table table-bordered table-condensed">
    <thead>
      <tr>
        <th>Type</th>
        <th>Description</th>
      </tr>
    </thead>
    <tbody>
      <tr>
        <td><a class="xref" href="https://learn.microsoft.com/dotnet/api/system.int32">int</a></td>
        <td></td>
      </tr>
    </tbody>
  </table>
  <h5 id="VulcanAI_Core_LLM_LocalLLMClient_MaxPromptLength_remarks">Remarks</h5>
  <div class="markdown level1 remarks"><p>This value is used to validate prompts before sending them to the LLM.
The default value is 4096 tokens, which is a common limit for many language models.</p>
</div>
  <h3 id="methods">Methods
</h3>
  <span class="small pull-right mobile-hide">
    <span class="divider">|</span>
    <a href="https://github.com/StevenGann/VulcanAI/new/main/apiSpec/new?filename=VulcanAI_Core_LLM_LocalLLMClient_GetCompletionAsync_System_String_.md&amp;value=---%0Auid%3A%20VulcanAI.Core.LLM.LocalLLMClient.GetCompletionAsync(System.String)%0Asummary%3A%20&#39;*You%20can%20override%20summary%20for%20the%20API%20here%20using%20*MARKDOWN*%20syntax&#39;%0A---%0A%0A*Please%20type%20below%20more%20information%20about%20this%20API%3A*%0A%0A">Edit this page</a>
  </span>
  <span class="small pull-right mobile-hide">
    <a href="https://github.com/StevenGann/VulcanAI/blob/main/VulcanAI/Core/LLM/LocalLLMClient.cs/#L254">View Source</a>
  </span>
  <a id="VulcanAI_Core_LLM_LocalLLMClient_GetCompletionAsync_" data-uid="VulcanAI.Core.LLM.LocalLLMClient.GetCompletionAsync*"></a>
  <h4 id="VulcanAI_Core_LLM_LocalLLMClient_GetCompletionAsync_System_String_" data-uid="VulcanAI.Core.LLM.LocalLLMClient.GetCompletionAsync(System.String)">GetCompletionAsync(string)</h4>
  <div class="markdown level1 summary"><p>Gets a completion from the language model.</p>
</div>
  <div class="markdown level1 conceptual"></div>
  <h5 class="declaration">Declaration</h5>
  <div class="codewrapper">
    <pre><code class="lang-csharp hljs">public Task&lt;string&gt; GetCompletionAsync(string prompt)</code></pre>
  </div>
  <h5 class="parameters">Parameters</h5>
  <table class="table table-bordered table-condensed">
    <thead>
      <tr>
        <th>Type</th>
        <th>Name</th>
        <th>Description</th>
      </tr>
    </thead>
    <tbody>
      <tr>
        <td><a class="xref" href="https://learn.microsoft.com/dotnet/api/system.string">string</a></td>
        <td><span class="parametername">prompt</span></td>
        <td><p>The prompt to send to the language model.</p>
</td>
      </tr>
    </tbody>
  </table>
  <h5 class="returns">Returns</h5>
  <table class="table table-bordered table-condensed">
    <thead>
      <tr>
        <th>Type</th>
        <th>Description</th>
      </tr>
    </thead>
    <tbody>
      <tr>
        <td><a class="xref" href="https://learn.microsoft.com/dotnet/api/system.threading.tasks.task-1">Task</a>&lt;<a class="xref" href="https://learn.microsoft.com/dotnet/api/system.string">string</a>&gt;</td>
        <td><p>A task that represents the asynchronous operation. The task result contains the model's response.</p>
</td>
      </tr>
    </tbody>
  </table>
  <h5 id="VulcanAI_Core_LLM_LocalLLMClient_GetCompletionAsync_System_String__remarks">Remarks</h5>
  <div class="markdown level1 remarks"><p>This method sends a prompt to the language model and returns its response.
The response format depends on whether the client is configured to use the OpenAI-compatible format
or the LM Studio format. In either case, the method extracts the completion text from the response
and returns it as a string.</p>
</div>
  <h5 class="exceptions">Exceptions</h5>
  <table class="table table-bordered table-condensed">
    <thead>
      <tr>
        <th>Type</th>
        <th>Condition</th>
      </tr>
    </thead>
    <tbody>
      <tr>
        <td><a class="xref" href="https://learn.microsoft.com/dotnet/api/system.argumentnullexception">ArgumentNullException</a></td>
        <td><p>Thrown when the prompt is null or empty.</p>
</td>
      </tr>
      <tr>
        <td><a class="xref" href="https://learn.microsoft.com/dotnet/api/system.invalidoperationexception">InvalidOperationException</a></td>
        <td><p>Thrown when the prompt exceeds the maximum length or when no completion is returned.</p>
</td>
      </tr>
    </tbody>
  </table>
  <span class="small pull-right mobile-hide">
    <span class="divider">|</span>
    <a href="https://github.com/StevenGann/VulcanAI/new/main/apiSpec/new?filename=VulcanAI_Core_LLM_LocalLLMClient_GetCompletionAsync__1_System_String_System_Collections_Generic_Dictionary_System_String_System_Object__.md&amp;value=---%0Auid%3A%20VulcanAI.Core.LLM.LocalLLMClient.GetCompletionAsync%60%601(System.String%2CSystem.Collections.Generic.Dictionary%7BSystem.String%2CSystem.Object%7D)%0Asummary%3A%20&#39;*You%20can%20override%20summary%20for%20the%20API%20here%20using%20*MARKDOWN*%20syntax&#39;%0A---%0A%0A*Please%20type%20below%20more%20information%20about%20this%20API%3A*%0A%0A">Edit this page</a>
  </span>
  <span class="small pull-right mobile-hide">
    <a href="https://github.com/StevenGann/VulcanAI/blob/main/VulcanAI/Core/LLM/LocalLLMClient.cs/#L322">View Source</a>
  </span>
  <a id="VulcanAI_Core_LLM_LocalLLMClient_GetCompletionAsync_" data-uid="VulcanAI.Core.LLM.LocalLLMClient.GetCompletionAsync*"></a>
  <h4 id="VulcanAI_Core_LLM_LocalLLMClient_GetCompletionAsync__1_System_String_System_Collections_Generic_Dictionary_System_String_System_Object__" data-uid="VulcanAI.Core.LLM.LocalLLMClient.GetCompletionAsync``1(System.String,System.Collections.Generic.Dictionary{System.String,System.Object})">GetCompletionAsync&lt;T&gt;(string, Dictionary&lt;string, object&gt;?)</h4>
  <div class="markdown level1 summary"><p>Gets a completion from the LLM and deserializes it into the specified type</p>
</div>
  <div class="markdown level1 conceptual"></div>
  <h5 class="declaration">Declaration</h5>
  <div class="codewrapper">
    <pre><code class="lang-csharp hljs">public Task&lt;T&gt; GetCompletionAsync&lt;T&gt;(string prompt, Dictionary&lt;string, object&gt;? options = null) where T : class</code></pre>
  </div>
  <h5 class="parameters">Parameters</h5>
  <table class="table table-bordered table-condensed">
    <thead>
      <tr>
        <th>Type</th>
        <th>Name</th>
        <th>Description</th>
      </tr>
    </thead>
    <tbody>
      <tr>
        <td><a class="xref" href="https://learn.microsoft.com/dotnet/api/system.string">string</a></td>
        <td><span class="parametername">prompt</span></td>
        <td><p>The prompt to send to the LLM</p>
</td>
      </tr>
      <tr>
        <td><a class="xref" href="https://learn.microsoft.com/dotnet/api/system.collections.generic.dictionary-2">Dictionary</a>&lt;<a class="xref" href="https://learn.microsoft.com/dotnet/api/system.string">string</a>, <a class="xref" href="https://learn.microsoft.com/dotnet/api/system.object">object</a>&gt;</td>
        <td><span class="parametername">options</span></td>
        <td><p>Additional options for the completion</p>
</td>
      </tr>
    </tbody>
  </table>
  <h5 class="returns">Returns</h5>
  <table class="table table-bordered table-condensed">
    <thead>
      <tr>
        <th>Type</th>
        <th>Description</th>
      </tr>
    </thead>
    <tbody>
      <tr>
        <td><a class="xref" href="https://learn.microsoft.com/dotnet/api/system.threading.tasks.task-1">Task</a>&lt;T&gt;</td>
        <td><p>The deserialized completion</p>
</td>
      </tr>
    </tbody>
  </table>
  <h5 class="typeParameters">Type Parameters</h5>
  <table class="table table-bordered table-condensed">
    <thead>
      <tr>
        <th>Name</th>
        <th>Description</th>
      </tr>
    </thead>
    <tbody>
      <tr>
        <td><span class="parametername">T</span></td>
        <td><p>The type to deserialize the completion into</p>
</td>
      </tr>
    </tbody>
  </table>
  <h5 class="exceptions">Exceptions</h5>
  <table class="table table-bordered table-condensed">
    <thead>
      <tr>
        <th>Type</th>
        <th>Condition</th>
      </tr>
    </thead>
    <tbody>
      <tr>
        <td><a class="xref" href="https://learn.microsoft.com/dotnet/api/system.argumentnullexception">ArgumentNullException</a></td>
        <td><p>Thrown when the prompt is null or empty</p>
</td>
      </tr>
      <tr>
        <td><a class="xref" href="https://learn.microsoft.com/dotnet/api/system.invalidoperationexception">InvalidOperationException</a></td>
        <td><p>Thrown when the prompt length exceeds MaxPromptLength or deserialization fails</p>
</td>
      </tr>
    </tbody>
  </table>
  <h3 id="implements">Implements</h3>
  <div>
      <a class="xref" href="VulcanAI.Core.LLM.ILLMClient.html">ILLMClient</a>
  </div>

</article>
          </div>

          <div class="hidden-sm col-md-2" role="complementary">
            <div class="sideaffix">
              <div class="contribution">
                <ul class="nav">
                  <li>
                    <a href="https://github.com/StevenGann/VulcanAI/new/main/apiSpec/new?filename=VulcanAI_Core_LLM_LocalLLMClient.md&amp;value=---%0Auid%3A%20VulcanAI.Core.LLM.LocalLLMClient%0Asummary%3A%20&#39;*You%20can%20override%20summary%20for%20the%20API%20here%20using%20*MARKDOWN*%20syntax&#39;%0A---%0A%0A*Please%20type%20below%20more%20information%20about%20this%20API%3A*%0A%0A" class="contribution-link">Edit this page</a>
                  </li>
                  <li>
                    <a href="https://github.com/StevenGann/VulcanAI/blob/main/VulcanAI/Core/LLM/LocalLLMClient.cs/#L20" class="contribution-link">View Source</a>
                  </li>
                </ul>
              </div>
              <nav class="bs-docs-sidebar hidden-print hidden-xs hidden-sm affix" id="affix">
                <h5>In this article</h5>
                <div></div>
              </nav>
            </div>
          </div>
        </div>
      </div>

      <footer>
        <div class="grad-bottom"></div>
        <div class="footer">
          <div class="container">
            <span class="pull-right">
              <a href="#top">Back to top</a>
            </span>
      
      <span>Generated by <strong>DocFX</strong></span>
          </div>
        </div>
      </footer>
    </div>

    <script type="text/javascript" src="../styles/docfx.vendor.min.js"></script>
    <script type="text/javascript" src="../styles/docfx.js"></script>
    <script type="text/javascript" src="../styles/main.js"></script>
  </body>
</html>
